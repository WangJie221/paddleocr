{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjie/miniconda3/envs/paddle/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "\n",
    "ROOT = Path(os.path.relpath('__file__')).resolve().parents[1]\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjie/miniconda3/envs/paddle/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/wangjie/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/wangjie/.paddlex/official_models/PP-OCRv5_server_rec`.\u001b[0m\n",
      "\u001b[32m{'res': {'input_path': '/home/wangjie/programs/PaddleOCR/data/RL.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': False}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': False, 'use_doc_unwarping': False}, 'angle': -1}, 'dt_polys': array([], dtype=float64), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': [], 'rec_scores': array([], dtype=float64), 'rec_polys': array([], dtype=float64), 'rec_boxes': array([], dtype=float64)}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "img_path = str(ROOT / 'data/RL.png')\n",
    "\n",
    "ocr = PaddleOCR(\n",
    "    use_doc_orientation_classify=False, \n",
    "    use_doc_unwarping=False, \n",
    "    use_textline_orientation=False) # 文本检测+文本识别\n",
    "# ocr = PaddleOCR(use_doc_orientation_classify=True, use_doc_unwarping=True) # 文本图像预处理+文本检测+方向分类+文本识别\n",
    "# ocr = PaddleOCR(use_doc_orientation_classify=False, use_doc_unwarping=False) # 文本检测+文本行方向分类+文本识别\n",
    "# ocr = PaddleOCR(\n",
    "#     text_detection_model_name=\"PP-OCRv5_mobile_det\",\n",
    "#     text_recognition_model_name=\"PP-OCRv5_mobile_rec\",\n",
    "#     use_doc_orientation_classify=False,\n",
    "#     use_doc_unwarping=False,\n",
    "#     use_textline_orientation=False) # 更换 PP-OCRv5_mobile 模型\n",
    "result = ocr.predict(img_path)\n",
    "for res in result:\n",
    "    res.print()\n",
    "    res.save_to_img(\"output\")\n",
    "    res.save_to_json(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 服务化部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paddlex --install serving\n",
    "# paddlex --serve --pipeline OCR --port 8012\n",
    "\n",
    "# apt install fonts-wqy-microhei # 安装中文字体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_settings': {'use_doc_preprocessor': False, 'use_textline_orientation': True}, 'dt_polys': [], 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': [], 'rec_scores': [], 'rec_polys': [], 'rec_boxes': []}\n"
     ]
    }
   ],
   "source": [
    "# 测试服务化部署\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:8012/ocr\"\n",
    "image_path = str(ROOT / 'data/RL.png')\n",
    "\n",
    "with open(image_path, \"rb\") as file:\n",
    "   file_data = base64.b64encode(file.read()).decode(\"ascii\")\n",
    "# payload = {\"file\": file_data, \"fileType\": 1, \"visualize\": True}\n",
    "payload = {\"file\": file_data, \"fileType\": 1, \"visualize\": False, \"useDocUnwarping\": False}\n",
    "response = requests.post(API_URL, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()[\"result\"]\n",
    "for i, res in enumerate(result[\"ocrResults\"]):\n",
    "    print(res[\"prunedResult\"])\n",
    "    # ocr_img_path = f\"ocr_{i}.jpg\"\n",
    "    # with open(ocr_img_path, \"wb\") as f:\n",
    "    #     f.write(base64.b64decode(res[\"ocrImage\"]))\n",
    "    # print(f\"Output image saved at {ocr_img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response.json()['result']['ocrResults'][0]['prunedResult']\n",
    "dt_polys = result['dt_polys']\n",
    "rec_polys = result['rec_polys']\n",
    "rec_texts= result['rec_texts']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制单个检测框\n",
    "# img = cv2.imread(image_path)\n",
    "# box = np.asarray(dt_polys[0])\n",
    "\n",
    "# cv2.polylines(img, [box], True, (0, 255, 0), 1)\n",
    "\n",
    "# # 添加文本标签\n",
    "# center_x = int(np.mean(box[:, 0]))\n",
    "# center_y = int(np.mean(box[:, 1]))\n",
    "# cv2.putText(img, str(rec_texts[0]), (center_x, center_y), \n",
    "#             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            \n",
    "# Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PPOCRLabel数据标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip3 install PPOCRLabel\n",
    "pip3 install trash-cli\n",
    "export QT_QPA_PALTFORM=wayland # 可以考虑添加到系统环境变量中，避免多次输入\n",
    "# 选择标签模式来启动\n",
    "PPOCRLabel --lang ch  # 启动【普通模式】，用于打【检测+识别】场景的标签\n",
    "PPOCRLabel --lang ch --kie True  # 启动 【KIE 模式】，用于打【检测+识别+关键字提取】场景的标签\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradio前端界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont\n",
    "import base64\n",
    "\n",
    "from ocr_annotator import OCRAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'image_pil' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m annotator = OCRAnnotator(API_URL)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mannotator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_ocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/PaddleOCR/notebooks/ocr_annotator.py:74\u001b[39m, in \u001b[36mOCRAnnotator.perform_ocr\u001b[39m\u001b[34m(self, image_path)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.current_texts = result[\u001b[33m'\u001b[39m\u001b[33mrec_texts\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# 识别文本\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mself\u001b[39m.confidences = result[\u001b[33m'\u001b[39m\u001b[33mrec_scores\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# 置信度\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_annotation_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/PaddleOCR/notebooks/ocr_annotator.py:110\u001b[39m, in \u001b[36mOCRAnnotator._create_annotation_image\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m     draw.text((text_x, text_y), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.current_texts[i]), font=font, fill=(\u001b[32m255\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m))\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# 转换回 OpenCV 格式\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m img_with_boxes = cv2.cvtColor(np.array(\u001b[43mimage_pil\u001b[49m), cv2.COLOR_RGB2BGR)\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# 保存临时结果图像\u001b[39;00m\n\u001b[32m    113\u001b[39m timestamp = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(time.time()))\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'image_pil' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "annotator = OCRAnnotator(API_URL)\n",
    "annotator.perform_ocr(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016',\n",
       " '2019',\n",
       " 'AlphaGo战李世石',\n",
       " 'Alpha Star 登上Nature',\n",
       " 'Alpha Go 挑战世界冠军韩国职业',\n",
       " '已经达到星际争霸2人类对战天',\n",
       " '棋手李世石，以4：1的结果取胜',\n",
       " '梯的顶级水平',\n",
       " '环境 Environment',\n",
       " '动作Action',\n",
       " '状态 State',\n",
       " '奖励Reward',\n",
       " '序列决策',\n",
       " '长期收益',\n",
       " '强化学习',\n",
       " '智能体Agent']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator.current_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.splitext(os.path.basename(annotator.image_path))[0]\n",
    "# json_path = os.path.join(output_dir, f\"{base_name}_annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RL'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(os.path.basename(annotator.image_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    115\u001b[39m     save_btn.click(\n\u001b[32m    116\u001b[39m         fn=save_annotations_handler,\n\u001b[32m    117\u001b[39m         outputs=message_output\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[43mdemo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0.0.0.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7860\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/miniconda/envs/paddle/lib/python3.11/site-packages/gradio/blocks.py:2635\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[39m\n\u001b[32m   2627\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2628\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m http_server\n\u001b[32m   2630\u001b[39m     (\n\u001b[32m   2631\u001b[39m         server_name,\n\u001b[32m   2632\u001b[39m         server_port,\n\u001b[32m   2633\u001b[39m         local_url,\n\u001b[32m   2634\u001b[39m         server,\n\u001b[32m-> \u001b[39m\u001b[32m2635\u001b[39m     ) = \u001b[43mhttp_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m     \u001b[38;5;28mself\u001b[39m.server_name = server_name\n\u001b[32m   2644\u001b[39m     \u001b[38;5;28mself\u001b[39m.local_url = local_url\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/miniconda/envs/paddle/lib/python3.11/site-packages/gradio/http_server.py:157\u001b[39m, in \u001b[36mstart_server\u001b[39m\u001b[34m(app, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot find empty port in range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ssl_keyfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    162\u001b[39m     path_to_local_server = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_host_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "# 创建标注器实例\n",
    "annotator = OCRAnnotator(API_URL)\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"处理上传的图像\"\"\"\n",
    "    # 保存上传的图像\n",
    "    if isinstance(image, str):\n",
    "        image_path = image\n",
    "    else:\n",
    "        image_path = \"uploaded_image.jpg\"\n",
    "        image.save(image_path)\n",
    "    \n",
    "    # 执行OCR\n",
    "    result_image = annotator.perform_ocr(image_path)\n",
    "    annotation_data = annotator.get_annotation_data()\n",
    "    \n",
    "    # 创建数据表格\n",
    "    data_table = []\n",
    "    for item in annotation_data:\n",
    "        data_table.append([item[\"id\"], item[\"text\"], str(item[\"bbox\"])])\n",
    "    \n",
    "    return result_image, data_table\n",
    "\n",
    "def update_text_handler(id, new_text):\n",
    "    \"\"\"更新文本处理器\"\"\"\n",
    "    success = annotator.update_text(id, new_text)\n",
    "    if success:\n",
    "        result_image = annotator._create_annotation_image()\n",
    "        annotation_data = annotator.get_annotation_data()\n",
    "        \n",
    "        data_table = []\n",
    "        for item in annotation_data:\n",
    "            data_table.append([item[\"id\"], item[\"text\"], str(item[\"bbox\"])])\n",
    "        \n",
    "        return result_image, data_table, f\"文本ID {id} 更新成功\"\n",
    "    else:\n",
    "        return gr.update(), gr.update(), f\"文本ID {id} 更新失败\"\n",
    "\n",
    "def delete_box_handler(id):\n",
    "    \"\"\"删除框处理器\"\"\"\n",
    "    success = annotator.delete_box(id)\n",
    "    if success:\n",
    "        result_image = annotator._create_annotation_image()\n",
    "        annotation_data = annotator.get_annotation_data()\n",
    "        \n",
    "        data_table = []\n",
    "        for item in annotation_data:\n",
    "            data_table.append([item[\"id\"], item[\"text\"], str(item[\"bbox\"])])\n",
    "        \n",
    "        return result_image, data_table, f\"框ID {id} 删除成功\"\n",
    "    else:\n",
    "        return gr.update(), gr.update(), f\"框ID {id} 删除失败\"\n",
    "\n",
    "def save_annotations_handler():\n",
    "    \"\"\"保存标注结果\"\"\"\n",
    "    if not annotator.current_boxes:\n",
    "        return \"没有可保存的标注数据\"\n",
    "    \n",
    "    output_dir = \"annotations\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(annotator.image_path))[0]\n",
    "    json_path = os.path.join(output_dir, f\"{base_name}_annotations.json\")\n",
    "    \n",
    "    json_path, txt_path = annotator.save_annotations(json_path)\n",
    "    return f\"标注结果已保存:\\nJSON: {json_path}\\nTXT: {txt_path}\"\n",
    "\n",
    "# 创建Gradio界面 :cite[2]:cite[6]\n",
    "with gr.Blocks(title=\"OCR数据标注系统\") as demo:\n",
    "    gr.Markdown(\"# OCR数据标注系统\")\n",
    "    gr.Markdown(\"上传图片进行OCR识别，然后对识别结果进行标注和编辑\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image_input = gr.Image(label=\"上传图片\", type=\"filepath\")\n",
    "            process_btn = gr.Button(\"执行OCR识别\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                text_id_input = gr.Number(label=\"文本ID\", precision=0)\n",
    "                new_text_input = gr.Textbox(label=\"新文本内容\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                update_text_btn = gr.Button(\"更新文本\")\n",
    "                delete_box_btn = gr.Button(\"删除框\")\n",
    "            \n",
    "            save_btn = gr.Button(\"保存标注结果\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            image_output = gr.Image(label=\"识别结果\")\n",
    "            data_table = gr.Dataframe(\n",
    "                headers=[\"ID\", \"识别文本\", \"坐标框\"],\n",
    "                label=\"识别结果表格\"\n",
    "            )\n",
    "            message_output = gr.Textbox(label=\"操作消息\", interactive=False)\n",
    "    \n",
    "    # 事件绑定\n",
    "    process_btn.click(\n",
    "        fn=process_image,\n",
    "        inputs=image_input,\n",
    "        outputs=[image_output, data_table]\n",
    "    )\n",
    "    \n",
    "    update_text_btn.click(\n",
    "        fn=update_text_handler,\n",
    "        inputs=[text_id_input, new_text_input],\n",
    "        outputs=[image_output, data_table, message_output]\n",
    "    )\n",
    "    \n",
    "    delete_box_btn.click(\n",
    "        fn=delete_box_handler,\n",
    "        inputs=text_id_input,\n",
    "        outputs=[image_output, data_table, message_output]\n",
    "    )\n",
    "    \n",
    "    save_btn.click(\n",
    "        fn=save_annotations_handler,\n",
    "        outputs=message_output\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
